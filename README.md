 This project aims to develop a machine learning model capable of predicting hand and finger movement from surface electromyography (sEMG) signals recorded from the forearm. The challenge lies in mapping complex muscle activation patterns to precise multi-joint finger positions, a relationship that is highly nonlinear. To address this, the project will use the NINAPRO dataset, which provides synchronized sEMG recordings and detailed hand kinematics collected through a CyberGlove system. A neural network model  will be trained to learn this mapping. The model will take windows of EMG data as input and output predicted joint angles for the fingers and hand. Performance will be evaluated using metrics such as RMSE, MAE, and correlation between predicted and true joint angles. Additional validation will include visual plots of predicted versus actual motion. 
